# -*- coding: utf-8 -*-
"""customer churn prediction using ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H1jD9yrb8gN8LltMvE29uRTRWG83pNHf

**1.Importing the dependencies**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split , cross_val_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import pickle

"""**2.Data loading ad understanding**"""

#load the csv data to panda dataframe
df=pd.read_csv("/content/WA_Fn-UseC_-Telco-Customer-Churn.csv")

df.shape

df.head()

#SETTING PANDAS TO PRINT EVERY COLUM WITHOUT ANY LIMIT
pd.set_option('display.max_columns', None)

df.head()

df.info()

#Dropping customer id column as it is not required for modelling
df = df.drop(columns = ['customerID'])

df.head()

df.columns

print(df["gender"].unique())

#Printing unique value in all the columns using for loop but excluding numerical features column
numerical_features_list = ['tenure', 'MonthlyCharges', 'TotalCharges']
for col in df.columns:
  if col not in numerical_features_list:
   print(col,df[col].unique())
   print("_"* 50)

#Pandas command for checking missing values (i.e., NaNs) in a DataFrame.
print(df.isnull().sum())

"""**when a column like "TotalCharges" is of type object (string), missing values represented as empty strings ("") will not be detected by functions like df.isnull() or df.dropna() because technically "" is still a string, not a NaN.**

**To handle this situation properly, here's a clean way to rewrite and handle the transformation, step by step **
"""

df[df["TotalCharges"]== " "]

len(df[df["TotalCharges"]== " "])

#replacing " " with 0.0
df["TotalCharges"] = df["TotalCharges"].replace({" " : "0.0"})

#Now converting the values into float
df["TotalCharges"] = df["TotalCharges"].astype(float)

df.info()

#checking the class distribution of target column
print(df["Churn"].value_counts())

"""**3.EXPLORATOTY DATA ANALYSIS (EDA)**"""

df.shape

df.columns

df.head(2)

df.describe()

"""**3.Numerical Features Analysis**

 understanding the distribution of the numerical features.

 a.Histogram
"""

def plot_histogram(df,column_name):
  plt.figure(figsize=(10,5))
  sns.histplot(data=df,x=column_name,kde=True)
  plt.title(f"Distribution of {column_name}")
#calculate the mean and median value of the column
  col_mean = df[column_name].mean()
  col_median = df[column_name].median()
#add vertical lines for mean and medians
  plt.axvline(col_mean,color='red',linestyle='--',label="mean")
  plt.axvline(col_median,color='green',linestyle='-',label="median")

  plt.legend()
  plt.show()

plot_histogram(df,"tenure")

plot_histogram(df,"MonthlyCharges")

plot_histogram(df,"TotalCharges")

""" b.Box Plot for numerical features"""

def plot_boxplot (df, column_name):
  plt.figure(figsize=(5,3))
  sns.boxplot(y=df [column_name])
  plt.title(f"box plot of {column_name}")
  plt.ylabel(column_name)
  plt.show()

plot_boxplot(df,"tenure")

plot_boxplot(df,"MonthlyCharges")

plot_boxplot(df,"TotalCharges")

"""**c. Corelation heat map for numerical columns**"""

#corelation matrix - heatmap
plt.figure(figsize=(8,4))
sns.heatmap(df[["tenure","MonthlyCharges","TotalCharges"]].corr(), annot=True,cmap='coolwarm',fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()

"""**d. Categorical features - analysis**"""

df.columns

df.info()
#only seniorcitizen coulmn is categorical integers column not categoerical object

#Creating a list of categorical object including senior citizen
object_cols = df.select_dtypes(include='object').columns.to_list()
object_cols = ["SeniorCitizen"] + object_cols
for col in object_cols:
  plt.figure(figsize=(5,3))
  sns.countplot(x=df[col])
  plt.title(f"count plot of {col}")
  plt.show()

"""**4.Data Processing**"""

df.head(3)

"""label encoding of target column (EX : YES - 1 ,NO - 0)"""

df["Churn"]= df["Churn"].replace({"Yes": 1,"No":0})

df.head(3)

print(df["Churn"].value_counts())

"""**Label encoding of cateogorical features**"""

#Identifying columns with objects data type
object_columns =  df.select_dtypes(include='object').columns

print(object_columns)

#Initialize a dictionary to save the encoders
encoders = {}

#apply label encoding and store the encoder
for column in object_columns:
  label_encoder = LabelEncoder()
  df[column] = label_encoder.fit_transform(df[column])
  encoders[column] =label_encoder

encoders

df.head()

"""**Training and Test Data Split**"""

#splitting the features and target
x= df.drop(columns=["Churn"])
y= df["Churn"]

print(x)

print(y)

#split traing and test data
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)

print(y_train.shape)

print(y_train.value_counts())

"""**synthetic minority oversampling technique(SMOTE)**"""

smote =SMOTE(random_state = 42)

x_train_smote , y_train_smote = smote.fit_resample(x_train,y_train)

print(y_train_smote.shape)

print(y_train.value_counts())

"""**5.Model Training**

**Training with default hyper Parameters**
"""

#dictionary of models
models = {
    "Decision Tree": DecisionTreeClassifier(random_state = 42),
    "Random Forest": RandomForestClassifier(random_state = 42),
    "XGBoost": XGBClassifier(random_state = 42)
}

#dictionar to store the cross validation
cv_scores = {}

#perform 5-fold cross validation for each model
for model_name, model in models.items():
  print(f"Training {model_name} with default parameters")
  scores = cross_val_score(model,x_train_smote,y_train_smote,cv=5, scoring= "accuracy")
  cv_scores[model_name] = scores
  print(f"(model_name)cross-validation accuracy: {np.mean(scores):.2f}")
  print("_"*70)

cv_scores

"""**Random Forest gives the highest accuracy compared to other models with default parameters**"""

rfc = RandomForestClassifier(random_state = 42)

rfc.fit(x_train_smote,y_train_smote)

"""**6.Model Evaluation**"""

#Evaluate on test data
y_test_pred = rfc.predict(x_test)

print("accuracy score:\n", accuracy_score(y_test,y_test_pred))
print("confusion matrix:\n", confusion_matrix(y_test,y_test_pred))
print("classification report:\n", classification_report(y_test,y_test_pred))

#save the trained model as pickle file
model_data = {"model" : rfc,"features_names": x.columns.tolist()}

with open("customer_churn_model.pkl","wb") as f:
  pickle.dump(model_data,f)

"""**7.Load the saved model and build a Predictive system**"""

#load the saved model and the features name
with open("customer_churn_model.pkl","rb") as f:
  model_data = pickle.load(f)

loaded_model = model_data["model"]
feature_names = model_data["features_names"]

print(loaded_model)

print(feature_names)

import pandas as pd
import pickle

input_data = {
    "gender": "Female",
    "SeniorCitizen": 0,
    "Partner": "Yes",
    "Dependents": "No",
    "tenure": 1,
    "PhoneService": "No",
    "MultipleLines": "No phone service",
    "InternetService": "DSL",
    "OnlineSecurity": "No",
    "OnlineBackup": "Yes",
    "DeviceProtection": "No",
    "TechSupport": "No",
    "StreamingTV": "No",
    "StreamingMovies": "No",
    "Contract": "Month-to-month",
    "PaperlessBilling": "Yes",
    "PaymentMethod": "Electronic check",
    "MonthlyCharges": 29.85,
    "TotalCharges": 29.85
}
input_data_df = pd.DataFrame([input_data])

with open("encoders.pkl", "rb") as f:
  encoders = pickle.load(f)

#encode categorical featires using the saved encoders
for column, encoder in encoders.items():
  if column in input_data_df.columns: # Check if the column exists in the input data
    # Convert the input data to the correct format expected by the encoder
    input_data_df[column] = input_data_df[column].apply(lambda x: encoder.transform([x])[0] if x in encoder.classes_ else -1)
    # Handle unseen data
    # input_data_df[column] = encoder.transform(input_data_df[column].astype(str)) # Alternative: convert to string if encoder was fitted on strings


#make a prediction
prediction = loaded_model.predict(input_data_df)
pred_prob = loaded_model.predict_proba(input_data_df)
print(prediction)

#results

print(f"Prediction: {'Churn' if prediction[0] == 1 else 'No Churn'}")
print (f"Prediciton Probability: {pred_prob}")